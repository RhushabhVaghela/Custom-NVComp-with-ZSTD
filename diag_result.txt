========================================
Compressible Data Validation Tests
========================================

Objective: Prove system DOES compress when given compressible data
Context: benchmark_lz77 showed 'zero sequences' with random data


=== Testing: JSON Pattern (64KB) ===
Input size: 65536 bytes
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DIAG] compress: temp_size=11534336, total_used=7407104, remaining=4127232
[DIAG] sizeof(Match)=16, sizeof(ParseCost)=8, sizeof(Sequence)=16
[DIAG] block_size=65536, num_blocks=1, input_size=65536
[DIAG] Element offset calculation: block_idx * block_size = 0 * 65536 = 0
[DIAG] call_workspace.d_matches base = 0x90bf80000
[DIAG] call_workspace.d_costs base = 0x90c080000
[DIAG] block_ws.d_matches (after offset) = 0x90bf80000
[DIAG] block_ws.d_costs (after offset) = 0x90c080000
[DIAG] Pointer delta: d_matches offset = 0 bytes
[DIAG] recycled_matches = 0x90bf80000 (cast from block_ws.d_matches)
[DIAG] recycled_costs = 0x90c080000 (cast from block_ws.d_costs)
[DIAG] d_literal_lengths = 0x90bf80000
[DIAG] d_match_lengths = 0x90c000000
[DIAG] d_offsets = 0x90c080000
[DIAG] d_sequences = 0x90c6d0600
[DIAG] Expected offset for d_match_lengths: 512KB = 524288 bytes
[DIAG] Actual offset: match - lit = 524288 bytes

[PHASE2-START] Checking block_seq_ctxs[0] pointers:
[PHASE2-START] d_literal_lengths = 0x90bf80000
[PHASE2-START] d_match_lengths = 0x90c000000
[PHASE2-START] Offset: match - lit = 524288 bytes
[DEBUG] compress: Block 0 has num_sequences=3046
[DEBUG] compress: Calling build_sequences for block 0 with num_sequences=3046\n[DEBUG] First 5 sequences: [LL=419,ML=13,OF=264] [LL=55,ML=11,OF=264] [LL=18,ML=18,OF=462] [LL=24,ML=6,OF=330] [LL=15,ML=21,OF=330] 
[DEBUG] Pointers: d_lit=0x90bf80000, d_match=0x90c000000, d_off=0x90c080000, d_seq=0x90c6d0600
[DEBUG] Pointer deltas: match-lit=524288, off-lit=1048576
[DEBUG] build_sequences: d_sequences=0x90c6d0600, d_num_sequences=0x90c290080
[DEBUG] build_sequences: d_sequences=0x90c6d0600, d_num_sequences=0x90c290080
[DEBUG] build_sequences: d_sequences=0x90be2ab80, d_num_sequences=0x90bbe0000
[DEBUG] build_sequences: d_sequences=0x90be2ab80, d_num_sequences=0x90bbe0000
✅ Compressed: 43744 bytes
✅ Compression ratio: 1.50:1
✅ Round-trip verified!
✅ JSON pattern test PASSED

=== Testing: RLE Pattern (64KB) ===
Input size: 65536 bytes
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DIAG] compress: temp_size=11534336, total_used=7407104, remaining=4127232
[DIAG] sizeof(Match)=16, sizeof(ParseCost)=8, sizeof(Sequence)=16
[DIAG] block_size=65536, num_blocks=1, input_size=65536
[DIAG] Element offset calculation: block_idx * block_size = 0 * 65536 = 0
[DIAG] call_workspace.d_matches base = 0x902d80000
[DIAG] call_workspace.d_costs base = 0x902e80000
[DIAG] block_ws.d_matches (after offset) = 0x902d80000
[DIAG] block_ws.d_costs (after offset) = 0x902e80000
[DIAG] Pointer delta: d_matches offset = 0 bytes
[DIAG] recycled_matches = 0x902d80000 (cast from block_ws.d_matches)
[DIAG] recycled_costs = 0x902e80000 (cast from block_ws.d_costs)
[DIAG] d_literal_lengths = 0x902d80000
[DIAG] d_match_lengths = 0x902e00000
[DIAG] d_offsets = 0x902e80000
[DIAG] d_sequences = 0x9034d0600
[DIAG] Expected offset for d_match_lengths: 512KB = 524288 bytes
[DIAG] Actual offset: match - lit = 524288 bytes

[PHASE2-START] Checking block_seq_ctxs[0] pointers:
[PHASE2-START] d_literal_lengths = 0x902d80000
[PHASE2-START] d_match_lengths = 0x902e00000
[PHASE2-START] Offset: match - lit = 524288 bytes
[DEBUG] compress: Block 0 has num_sequences=436
[DEBUG] compress: Calling build_sequences for block 0 with num_sequences=436\n[DEBUG] First 5 sequences: [LL=2591,ML=128,OF=40] [LL=8,ML=128,OF=168] [LL=43,ML=128,OF=787] [LL=13,ML=128,OF=915] [LL=0,ML=128,OF=3077] 
[DEBUG] Pointers: d_lit=0x902d80000, d_match=0x902e00000, d_off=0x902e80000, d_seq=0x9034d0600
[DEBUG] Pointer deltas: match-lit=524288, off-lit=1048576
[DEBUG] build_sequences: d_sequences=0x9034d0600, d_num_sequences=0x903090080
[DEBUG] build_sequences: d_sequences=0x9034d0600, d_num_sequences=0x903090080
[ERROR] build_sequences: Pre-existing error: invalid argument
test_compressible_data: /mnt/d/Research Experiments/TDPE_and_GPU_loading/NVComp with ZSTD/tests/test_compressible_data.cu:241: bool test_rle_pattern(): Assertion `result.compression_ratio > 10.0f && "RLE should compress extremely well"' failed.
