========================================
Compressible Data Validation Tests
========================================

Objective: Prove system DOES compress when given compressible data
Context: benchmark_lz77 showed 'zero sequences' with random data


=== Testing: JSON Pattern (64KB) ===
Input size: 65536 bytes
[DEBUG] test_compression: d_compressed allocated at 0x90ba10000
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DEBUG] compress: input_ptr=0x90ba00000, input_attr_err=0, type=2, input_is_device=1
[DEBUG] compress: d_output=0x90ba10000, max_size=131072
[DIAG] compress: temp_size=11534336, total_used=7407104, remaining=4127232
[DIAG] sizeof(Match)=16, sizeof(ParseCost)=8, sizeof(Sequence)=16
[DIAG] block_size=65536, num_blocks=1, input_size=65536
[DIAG] Element offset calculation: block_idx * block_size = 0 * 65536 = 0
[DIAG] call_workspace.d_matches base = 0x90bf80000
[DIAG] call_workspace.d_costs base = 0x90c080000
[DIAG] block_ws.d_matches (after offset) = 0x90bf80000
[DIAG] block_ws.d_costs (after offset) = 0x90c080000
[DIAG] Pointer delta: d_matches offset = 0 bytes
[DIAG] recycled_matches = 0x90bf80000 (cast from block_ws.d_matches)
[DIAG] recycled_costs = 0x90c080000 (cast from block_ws.d_costs)
[DIAG] d_literal_lengths = 0x90bf80000
[DIAG] d_match_lengths = 0x90c000000
[DIAG] d_offsets = 0x90c080000
[DIAG] d_sequences = 0x90c6d0600
[DIAG] Expected offset for d_match_lengths: 512KB = 524288 bytes
[DIAG] Actual offset: match - lit = 524288 bytes

[PHASE2-START] Checking block_seq_ctxs[0] pointers:
[PHASE2-START] d_literal_lengths = 0x90bf80000
[PHASE2-START] d_match_lengths = 0x90c000000
[PHASE2-START] Offset: match - lit = 524288 bytes
[DEBUG] compress: Block 0 has num_sequences=3036
[DEBUG] compress: Calling build_sequences for block 0 with num_sequences=3036\n[DEBUG] First 5 sequences: [LL=519,ML=15,OF=462] [LL=28,ML=3,OF=16] [LL=10,ML=25,OF=66] [LL=24,ML=6,OF=346] [LL=128,ML=9,OF=599] 
[DEBUG] Pointers: d_lit=0x90bf80000, d_match=0x90c000000, d_off=0x90c080000, d_seq=0x90c6d0600
[DEBUG] Pointer deltas: match-lit=524288, off-lit=1048576
[DEBUG] build_sequences: d_sequences=0x90c6d0600, d_num_sequences=0x90c290080
[DEBUG] build_sequences: d_sequences=0x90c6d0600, d_num_sequences=0x90c290080
[DEBUG] decompress_literals: d_output allocated at 0x90be0a900
[DEBUG] build_sequences: d_sequences=0x90be2a900, d_num_sequences=0x90bbe0000
[DEBUG] build_sequences: d_sequences=0x90be2a900, d_num_sequences=0x90bbe0000
✅ Compressed: 43138 bytes
✅ Compression ratio: 1.52:1
✅ Round-trip verified!
✅ JSON pattern test PASSED

=== Testing: RLE Pattern (64KB) ===
Input size: 65536 bytes
[DEBUG] test_compression: d_compressed allocated at 0x90ba00000
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DIAG] get_compress_temp_size: input=65536, total=11534336
[DEBUG] compress: input_ptr=0x90bbe0000, input_attr_err=0, type=2, input_is_device=1
[DEBUG] compress: d_output=0x90ba00000, max_size=131072
[DIAG] compress: temp_size=11534336, total_used=7407104, remaining=4127232
[ERROR] compress: Skippable Header copy failed: invalid argument
[DIAG] sizeof(Match)=16, sizeof(ParseCost)=8, sizeof(Sequence)=16
[DIAG] block_size=65536, num_blocks=1, input_size=65536
[DIAG] Element offset calculation: block_idx * block_size = 0 * 65536 = 0
[DIAG] call_workspace.d_matches base = 0x902d80000
[DIAG] call_workspace.d_costs base = 0x902e80000
[DIAG] block_ws.d_matches (after offset) = 0x902d80000
[DIAG] block_ws.d_costs (after offset) = 0x902e80000
[DIAG] Pointer delta: d_matches offset = 0 bytes
[DIAG] recycled_matches = 0x902d80000 (cast from block_ws.d_matches)
[DIAG] recycled_costs = 0x902e80000 (cast from block_ws.d_costs)
[DIAG] d_literal_lengths = 0x902d80000
[DIAG] d_match_lengths = 0x902e00000
[DIAG] d_offsets = 0x902e80000
[DIAG] d_sequences = 0x9034d0600
[DIAG] Expected offset for d_match_lengths: 512KB = 524288 bytes
[DIAG] Actual offset: match - lit = 524288 bytes

[PHASE2-START] Checking block_seq_ctxs[0] pointers:
[PHASE2-START] d_literal_lengths = 0x902d80000
[PHASE2-START] d_match_lengths = 0x902e00000
[PHASE2-START] Offset: match - lit = 524288 bytes
[DEBUG] compress: Block 0 has num_sequences=354
[DEBUG] compress: Calling build_sequences for block 0 with num_sequences=354\n[DEBUG] First 5 sequences: [LL=3234,ML=128,OF=1152] [LL=325,ML=128,OF=455] [LL=1326,ML=128,OF=2368] [LL=0,ML=128,OF=2656] [LL=0,ML=128,OF=2462] 
[DEBUG] Pointers: d_lit=0x902d80000, d_match=0x902e00000, d_off=0x902e80000, d_seq=0x9034d0600
[DEBUG] Pointer deltas: match-lit=524288, off-lit=1048576
[DEBUG] build_sequences: d_sequences=0x9034d0600, d_num_sequences=0x903090080
[DEBUG] build_sequences: d_sequences=0x9034d0600, d_num_sequences=0x903090080
test_compressible_data: /mnt/d/Research Experiments/TDPE_and_GPU_loading/NVComp with ZSTD/tests/test_compressible_data.cu:243: bool test_rle_pattern(): Assertion `result.compression_ratio > 10.0f && "RLE should compress extremely well"' failed.
